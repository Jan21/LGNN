{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intra-class edges percent: 0.9058\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl\n",
    "from dgl.data import citation_graph as citegrh\n",
    "\n",
    "data = citegrh.load_cora()\n",
    "\n",
    "G = dgl.DGLGraph(data.graph)\n",
    "labels = th.tensor(data.labels)\n",
    "\n",
    "# find all the nodes labeled with class 0\n",
    "label0_nodes = th.nonzero(labels == 1).squeeze()\n",
    "# find all the edges pointing to class 0 nodes\n",
    "src, _ = G.in_edges(label0_nodes)\n",
    "src_labels = labels[src]\n",
    "# find all the edges whose both endpoints are in class 0\n",
    "intra_src = th.nonzero(src_labels == 1)\n",
    "print('Intra-class edges percent: %.4f' % (len(intra_src) / len(src_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/jan/.dgl/cora_binary.zip from https://s3.us-east-2.amazonaws.com/dgl.ai/dataset/cora_binary.zip...\n",
      "Extracting file to /home/jan/.dgl/cora_binary\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_set = dgl.data.CoraBinary()\n",
    "G1, pmpd1, label1 = train_set[1]\n",
    "nx_G1 = G1.to_networkx()\n",
    "\n",
    "def visualize(labels, g):\n",
    "    pos = nx.spring_layout(g, seed=1)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.axis('off')\n",
    "    nx.draw_networkx(g, pos=pos, node_size=50, cmap=plt.get_cmap('coolwarm'),\n",
    "                     node_color=labels, edge_color='k',\n",
    "                     arrows=False, width=0.5, style='dotted', with_labels=False)\n",
    "visualize(label1, nx_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list containing features gathered from multiple radius.\n",
    "import dgl.function as fn\n",
    "def aggregate_radius(radius, g, z):\n",
    "    # initializing list to collect message passing result\n",
    "    z_list = []\n",
    "    g.ndata['z'] = z\n",
    "    # pulling message from 1-hop neighbourhood\n",
    "    g.update_all(fn.copy_src(src='z', out='m'), fn.sum(msg='m', out='z'))\n",
    "    z_list.append(g.ndata['z'])\n",
    "    for i in range(radius - 1):\n",
    "        for j in range(2 ** i):\n",
    "            #pulling message from 2^j neighborhood\n",
    "            g.update_all(fn.copy_src(src='z', out='m'), fn.sum(msg='m', out='z'))\n",
    "        z_list.append(g.ndata['z'])\n",
    "    return z_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGNNCore(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, radius):\n",
    "        super(LGNNCore, self).__init__()\n",
    "        self.out_feats = out_feats\n",
    "        self.radius = radius\n",
    "\n",
    "        self.linear_prev = nn.Linear(in_feats, out_feats)\n",
    "        self.linear_deg = nn.Linear(in_feats, out_feats)\n",
    "        self.linear_radius = nn.ModuleList(\n",
    "                [nn.Linear(in_feats, out_feats) for i in range(radius)])\n",
    "        self.linear_fuse = nn.Linear(in_feats, out_feats)\n",
    "        self.bn = nn.BatchNorm1d(out_feats)\n",
    "\n",
    "    def forward(self, g, feat_a, feat_b, deg, pm_pd):\n",
    "        # term \"prev\"\n",
    "        prev_proj = self.linear_prev(feat_a)\n",
    "        # term \"deg\"\n",
    "        deg_proj = self.linear_deg(deg * feat_a)\n",
    "\n",
    "        # term \"radius\"\n",
    "        # aggregate 2^j-hop features\n",
    "        hop2j_list = aggregate_radius(self.radius, g, feat_a)\n",
    "        # apply linear transformation\n",
    "        hop2j_list = [linear(x) for linear, x in zip(self.linear_radius, hop2j_list)]\n",
    "        radius_proj = sum(hop2j_list)\n",
    "\n",
    "        # term \"fuse\"\n",
    "        fuse = self.linear_fuse(th.mm(pm_pd, feat_b))\n",
    "\n",
    "        # sum them together\n",
    "        result = prev_proj + deg_proj + radius_proj + fuse\n",
    "\n",
    "        # skip connection and batch norm\n",
    "        n = self.out_feats // 2\n",
    "        result = th.cat([result[:, :n], F.relu(result[:, n:])], 1)\n",
    "        result = self.bn(result)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGNNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, radius):\n",
    "        super(LGNNLayer, self).__init__()\n",
    "        self.g_layer = LGNNCore(in_feats, out_feats, radius)\n",
    "        self.lg_layer = LGNNCore(in_feats, out_feats, radius)\n",
    "\n",
    "    def forward(self, g, lg, x, lg_x, deg_g, deg_lg, pm_pd):\n",
    "        next_x = self.g_layer(g, x, lg_x, deg_g, pm_pd)\n",
    "        pm_pd_y = th.transpose(pm_pd, 0, 1)\n",
    "        next_lg_x = self.lg_layer(lg, lg_x, x, deg_lg, pm_pd_y)\n",
    "        return next_x, next_lg_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGNN(nn.Module):\n",
    "    def __init__(self, radius):\n",
    "        super(LGNN, self).__init__()\n",
    "        self.layer1 = LGNNLayer(1, 16, radius)  # input is scalar feature\n",
    "        self.layer2 = LGNNLayer(16, 16, radius)  # hidden size is 16\n",
    "        self.layer3 = LGNNLayer(16, 16, radius)\n",
    "        self.linear = nn.Linear(16, 2)  # predice two classes\n",
    "\n",
    "    def forward(self, g, lg, pm_pd):\n",
    "        # compute the degrees\n",
    "        deg_g = g.in_degrees().float().unsqueeze(1)\n",
    "        deg_lg = lg.in_degrees().float().unsqueeze(1)\n",
    "        # use degree as the input feature\n",
    "        x, lg_x = deg_g, deg_lg\n",
    "        x, lg_x = self.layer1(g, lg, x, lg_x, deg_g, deg_lg, pm_pd)\n",
    "        x, lg_x = self.layer2(g, lg, x, lg_x, deg_g, deg_lg, pm_pd)\n",
    "        x, lg_x = self.layer3(g, lg, x, lg_x, deg_g, deg_lg, pm_pd)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "training_loader = DataLoader(train_set,\n",
    "                             batch_size=1,\n",
    "                             collate_fn=train_set.collate_fn,\n",
    "                             drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan/.conda/envs/mloncode/lib/python3.7/site-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | loss 0.5960 | accuracy 0.7055\n",
      "Epoch 1 | loss 0.5183 | accuracy 0.7742\n",
      "Epoch 2 | loss 0.4984 | accuracy 0.7713\n",
      "Epoch 3 | loss 0.4884 | accuracy 0.7703\n",
      "Epoch 4 | loss 0.4751 | accuracy 0.7846\n",
      "Epoch 5 | loss 0.4621 | accuracy 0.7829\n",
      "Epoch 6 | loss 0.4536 | accuracy 0.7901\n",
      "Epoch 7 | loss 0.4422 | accuracy 0.7940\n",
      "Epoch 8 | loss 0.4617 | accuracy 0.7657\n",
      "Epoch 9 | loss 0.4470 | accuracy 0.7981\n",
      "Epoch 10 | loss 0.4264 | accuracy 0.7991\n",
      "Epoch 11 | loss 0.4374 | accuracy 0.7911\n",
      "Epoch 12 | loss 0.4217 | accuracy 0.8066\n",
      "Epoch 13 | loss 0.4181 | accuracy 0.8108\n",
      "Epoch 14 | loss 0.4324 | accuracy 0.7994\n",
      "Epoch 15 | loss 0.4117 | accuracy 0.8115\n",
      "Epoch 16 | loss 0.4138 | accuracy 0.8155\n",
      "Epoch 17 | loss 0.4064 | accuracy 0.8144\n",
      "Epoch 18 | loss 0.4087 | accuracy 0.8152\n",
      "Epoch 19 | loss 0.3820 | accuracy 0.8232\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = LGNN(radius=3)\n",
    "# define the optimizer\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# a util function to convert a scipy.coo_matrix to torch.SparseFloat\n",
    "def sparse2th(mat):\n",
    "    value = mat.data\n",
    "    indices = th.LongTensor([mat.row, mat.col])\n",
    "    tensor = th.sparse.FloatTensor(indices, th.from_numpy(value).float(), mat.shape)\n",
    "    return tensor\n",
    "\n",
    "# train for 20 epochs\n",
    "for i in range(20):\n",
    "    all_loss = []\n",
    "    all_acc = []\n",
    "    for [g, pmpd, label] in training_loader:\n",
    "        # Generate the line graph.\n",
    "        lg = g.line_graph(backtracking=False)\n",
    "        # Create torch tensors\n",
    "        pmpd = sparse2th(pmpd)\n",
    "        label = th.from_numpy(label)\n",
    "\n",
    "        # Forward\n",
    "        z = model(g, lg, pmpd)\n",
    "\n",
    "        # Calculate loss:\n",
    "        # Since there are only two communities, there are only two permutations\n",
    "        #  of the community labels.\n",
    "        loss_perm1 = F.cross_entropy(z, label)\n",
    "        loss_perm2 = F.cross_entropy(z, 1 - label)\n",
    "        loss = th.min(loss_perm1, loss_perm2)\n",
    "\n",
    "        # Calculate accuracy:\n",
    "        _, pred = th.max(z, 1)\n",
    "        acc_perm1 = (pred == label).float().mean()\n",
    "        acc_perm2 = (pred == 1 - label).float().mean()\n",
    "        acc = th.max(acc_perm1, acc_perm2)\n",
    "        all_loss.append(loss.item())\n",
    "        all_acc.append(acc.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    niters = len(all_loss)\n",
    "    print(\"Epoch %d | loss %.4f | accuracy %.4f\" % (i,\n",
    "        sum(all_loss) / niters, sum(all_acc) / niters))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
